---
title: "산업공학특론I_13-14주차_산업데이터분석"
output: html_document
date: "2024-05-29"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<br>
<br>
<br>

## [데이터 분석 개요]
### 1. 대상 데이터: 다단계 공정 데이터셋
(https://www.kaggle.com/datasets/supergus/multistage-continuousflow-manufacturing-process)

미시간 주 디트로이트 근처의 실제 생산 라인 내에서 여러 위치, 여러 생산 라인에 대하여 계측한 데이터

다양한 입력 데이터로부터 라인의 출력 특정 속성을 예측하기 위한 목적으로 수집

해당 공정 라인은 병렬 및 직렬 단계로 구성된 고속 연속 제조 공정으로, 다음과 같은 구조를 가짐

* Stage 1에서는 M1, M2, M3 기계가 병렬로 작동하며, 이들의 출력이 결합기로 전달

* 결합기에서 출력되는 Stage 1에 대한 예측치는 제작된 제품의 외부 표면을 둘러싼 15개의 위치에서 측정

* 다음으로, M4와 M5가 직렬로 처리하는 Stage 2로 이동

* M5 작동 후에는 동일한 15개의 위치에 대한 Stage 2의 측정이 이루어짐

<br>

![](w13-14_fig.png)

<br>
* Oleghe, O. (2020). A predictive noise correction methodology for manufacturing process datasets. Journal of Big Data, 7(1), 89.

<br>
<br>
<br>

### 2. 분석 절차

데이터 탐색 및 전처리 / 특징 추출 및 차원 축소 / 모델 학습 및 평가 순서로 3단계로 나누어 분석 진행

2단계 공정인 관계로 Stage 1에 대한 예측모델, Stage 2에 대한 예측모델을 2단계로 모델링할 것 (이 때, Stage 2의 결과는 Stage 1에 영향을 받음)

원래 Stage 1, Stage 2에 대한 예측값은 각각 15개씩이지만, 본 강의에서는 다변량 예측을 다루지 않는 관계로 각 Stage에 대한 평균값을 종속변수로 설정

팀별로 작업을 수행하며, 작업 코드는 팀장의 Github에 Push하여 공유, 통찰력 있는 분석 기법 발굴 시 모두와 공유

가이드로 제공된 참고문헌을 바탕으로 다양한 방법론으로 분석을 수행

<br>
<br>
<br>

## [데이터 분석]
### 1. 데이터 탐색 및 전처리

* 데이터의 전반적인 분포, 특징을 파악하기 위한 기초 분석 진행

* 다양한 전처리 방법론을 활용하여 데이터를 정제
(e.g. 필요없는 변수 및 이상치/노이즈 제거 또는 보정, 표준화 등)

* 데이터 전처리 순서 (학습, 테스트셋 분할 전후)를 꼼꼼히 살펴보고 진행할 것

```{r preprocess}
library(corrplot)
library(ggplot2)
library(caret)

# 데이터 로드 및 전처리
dat <- read.csv("E:/Course/2024_lec_rstudio/실습/프로젝트실습/산업공학특론I_13-14주차_데이터.csv")
head(dat)

# stage 1과 stage2로 분리
stage1_m1 <- grep("Machine1", colnames(dat), value = TRUE)
stage1_m2 <- grep("Machine2", colnames(dat), value = TRUE)
stage1_m3 <- grep("Machine3", colnames(dat), value = TRUE)
stage1_co <- grep("FirstStage", colnames(dat), value = TRUE)

stage2_m4 <- grep("Machine4", colnames(dat), value = TRUE)
stage2_m5 <- grep("Machine5", colnames(dat), value = TRUE)

print(summary(dat[stage1_m1]))
print(summary(dat[stage1_m2]))
print(summary(dat[stage1_m3]))
print(summary(dat[stage1_co]))

print(summary(dat[stage2_m4]))
print(summary(dat[stage2_m5]))


# 각 Stage1, Stage2의 Actual의 평균 산출
stage1_output <- c()
stage2_output <- c()

st1 <- c('Stage1.Output')
st2 <- c('Stage2.Output')

for (i in colnames(dat)) {
  for (j in st1) {
    if (grepl(j, i) & grepl('Actual', i)) {
      stage1_output <- c(stage1_output, i)
    }
  }
  for (j in st2) {
    if (grepl(j, i) & grepl('Actual', i)) {
      stage2_output <- c(stage2_output, i)
    }
  }
}


stage1_label <- rowMeans(dat[, stage1_output], na.rm = TRUE)
stage2_label <- rowMeans(dat[, stage2_output], na.rm = TRUE)

dat["stage1_y"] <- stage1_label
dat["stage2_y"] <- stage2_label


# 데이터의 Missing value 확인
sum_na <- sum(is.na(dat))
print(sum_na)


# Correlation Matrix 계산
calculate_cor_matrix <- function(data) {
  # 표준편차 계산
  std_devs <- apply(data, 2, sd)
  
  # 표준편차가 0인 열 제거 <- 고정값으로 구성된 Stage2 Setpoint 제외
  data_clean <- data[, std_devs != 0]
  
  # 상관계수 행렬 계산
  cor_matrix <- cor(data_clean)
  
  return(cor_matrix)
}


draw_cor_plot <- function(col_list){
  
  i <- c(col_list, "stage1_y", "stage2_y")
  cor_dat <- calculate_cor_matrix(dat[,i])
  
  # 상관계수 행렬 출력
  print(cor_dat)
  
  # 상관계수 행렬 시각화
  corrplot(cor_dat, method = "circle", tl.cex = 0.1, cl.cex = 0.5,
           order = "hclust")
}

draw_cor_plot(stage1_m1)
draw_cor_plot(stage1_m2)
draw_cor_plot(stage1_m3)
draw_cor_plot(stage1_co)
draw_cor_plot(stage2_m4)
draw_cor_plot(stage2_m5)


# 표준편차가 0인 열
std_devs <- apply(dat, 2, sd)
std_0 <- names(std_devs[std_devs == 0])
print(std_0)

drop_list <- std_0[2:16]

final_data <- dat[,c(col_list,"stage1_y", "stage2_y")]

set.seed(0)

trainidx <- sample(1:nrow(final_data), 0.8*nrow(final_data))
trainset <- final_data[trainidx,]
testset <- final_data[-trainidx,]

colnames(trainset)
scaling <- preProcess(trainset[,-ncol(trainset)],
                      method = c('center','scale'))
trainsc <- predict(scaling, trainset[,-ncol(trainset)])
testsc <- predict(scaling, testset[,-ncol(testset)])

trainsc$stage1_y <- trainset$stage1_y
testsc$stage2_y <- testset$stage2_y

```

<br>

### 2. 특징 추출 및 차원 축소

* 전처리가 이루어진 데이터로부터 특성을 재정의하거나 차원 축소 기법을 적용

* 신규 변수 또는 축소된 차원으로 효과적인 예측을 수행하기 위한 방안 도출

```{r feature}

```

<br>

### 3. 모델 학습 및 평가

* Stage 1, Stage 2에 대한 예측 모델을 수립할 것

* 이 때, 각 Stage는 연결되어 있으며 Stage 2는 Stage 1의 영향을 받음

```{r modeling}

```
