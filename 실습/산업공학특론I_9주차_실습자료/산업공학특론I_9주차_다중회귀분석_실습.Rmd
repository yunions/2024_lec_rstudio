---
title: '산업공학특론I_9주차_다중회귀분석_실습'
author: 'Munwon Lim'
date: '5/1/2024'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.width=9, fig.height=9)
```

<br>
<br>
<br>



## [데이터 분석]

(https://www.kaggle.com/datasets/rukenmissonnier/manufacturing-data-for-polynomial-regression?resource=download)

다양한 공정 환경과 제품 품질 간의 관계를 탐색하기 위한 데이터셋

공정 조건을 나타내는 변수와 제조된 항목의 품질 등급을 나타내는 변수를 모두 포함

* TemperatureC: 제조 공정 중 측정된 섭씨 온도
* PressurekPa: 제조 공정 중 가해진 압력을 킬로파스칼 (kPa) 단위로 측정
* TemperaturexPressure: 온도와 압력 사이의 상호 작용, 두 공정 변수의 결합된 영향을 고려
* MaterialFusionMetric: 온도의 제곱과 압력의 세제곱의 합으로 계산된 파생 메트릭 - 제조 공정 중 재료 융합 관련 측정값
* MaterialTransformationMetric: 온도의 세제곱에서 압력의 제곱을 뺀 것으로 계산된 다른 파생 메트릭 - 재료 변형 역학 관련 측정값
* Quality Rating: 생산된 항목의 전체 품질 등급으로, 최종 제품의 품질을 측정하는 지표

<br>
<br>
<br>

### 1. 데이터 탐색 (EDA) 및 전처리
```{r eda}

# 데이터 로드 및 요약
dat <- read.csv("산업공학특론I_9주차_실습 데이터.csv")
summary(dat)

# 데이터 전처리
colnames(dat) <- gsub("[.]","", colnames(dat))
summary(dat)

# 학습, 테스트셋 분할
set.seed(0)

trainidx <- sample(1:nrow(dat), 0.8*nrow(dat))
train <- dat[trainidx,]
test <- dat[-trainidx,]

# 데이터 시각화
plot(train)

```

<br>

### 2. 상관분석
```{r correlation}
library(corrplot)

# 상관계수 테이블 생성
corr <- cor(train, method = "pearson")

# 상관계수 테이블 시각화
col <- colorRampPalette(c('dark red','dark blue'))
corrplot(corr, method='color',col=col(200),type='upper', addCoef.col="white")

```

<br>

### 3. 다중회귀분석

```{r regression}

# 다중회귀모형 수립
# 1) CV 수행 X
reg <- lm(QualityRating ~., data=train)
summary(reg)

# 2) CV 수행 O
library(caret)
train_cv <- trainControl(method = "cv", number=10)

reg_cv <- train(QualityRating ~ ., data=train, method='lm',
                trControl=train_cv)
reg_cv

# 모델 수립 결과
summary(reg_cv)

```


<br>

### 4. 변수선택법

```{r variableselection}

# 변수선택법 시행
# 1) CV 수행 X
reg_step1 <- step(reg, direction = "forward")
reg_step2 <- step(reg, direction = "backward")
reg_step3 <- step(reg, direction = "both")

# 2) CV 수행 O
reg_step1_cv <- train(QualityRating ~ ., data=train, method="glmStepAIC",
                     trControl=train_cv, direaction="forward",trace=FALSE)
reg_step2_cv <- train(QualityRating ~ ., data=train, method="glmStepAIC",
                     trControl=train_cv, direaction="backward",trace=FALSE)
reg_step3_cv <- train(QualityRating ~ ., data=train, method="glmStepAIC",
                     trControl=train_cv, direaction="both",trace=FALSE)


# 모델 수립 결과
summary(reg_step1)
summary(reg_step2)
summary(reg_step3)

summary(reg_step1_cv)
summary(reg_step2_cv)
summary(reg_step3_cv)

```


<br>

### 5. 정규화 회귀분석

```{r regularization}
library(glmnet)

# 정규화 회귀모형 수립
# 1) CV 수행 X
x <- as.matrix(train[,1:5]); y <- as.matrix(train[,6])

# lasso <- l1 Ridge <- l2
lasso <- glmnet(x,y, alpha=1)
ridge <- glmnet(x,y, alpha=0)
elastic <- glmnet(x,y, alpha=0.5)

par(mfrow=c(3,1))
plot(lasso, xvar='lambda')
legend('bottomright',legend = colnames(x), col = 1:5, lty=1)
plot(ridge, xvar='lambda')
legend('bottomright',legend = colnames(x), col = 1:5, lty=1)
plot(elastic, xvar='lambda')
legend('bottomright',legend = colnames(x), col = 1:5, lty=1)

# 2) CV 수행 O
lasso_cv <- cv.glmnet(x,y, alpha=1)
ridge_cv <- cv.glmnet(x,y, alpha=0)
elastic_cv <- cv.glmnet(x,y, alpha=0.5)

par(mfrow=c(3,1))
plot(lasso_cv)
plot(ridge_cv)
plot(elastic_cv)

# 모델 수립 결과
coef(lasso_cv)
coef(ridge_cv)
coef(elastic_cv)

```

<br>

### 6. 모형 평가 

```{r evaluation}

# 적합결과 평가 (학습모형 대상, 정규화 회귀분석은 AIC 평가 불가능)
regeval <- function(regr){
  summ <- summary(regr)
  mse <- summ$sigma^2
  adjrsq <- summ$adj.r.squared
  aic <- AIC(regr)
  
  result <- c(mse, adjrsq, aic)
  names(result) <- c("MSE","Adj Rsq","AIC")
  print(result)
}

regeval(reg)
regeval(reg_step2) # step2가 더 우수

# 직접 선언
pred <- predict(lasso_cv, x)
sse <- sum((pred-y)^2)
ssr <- sum((pred-mean(y))^2)
sst <- sse+ssr
mse <- sse/(nrow(x)-length(reg$coef))

adjrsq <- 1-(nrow(x)-1)/(nrow(x)-length(reg$coef))*ssr/sst
print(c(mse, adjrsq))


# 예측력 평가 (테스트셋 대상)
library(Metrics)
pred_reg1 <- predict(reg, test)

regresult1 <- c(mae(pred_reg1, test$QualityRating),mse(pred_reg1, test$QualityRating),
               rmse(pred_reg1, test$QualityRating))

pred_reg2 <- predict(reg_step2, test)

regresult2 <- c(mae(pred_reg2, test$QualityRating),mse(pred_reg2, test$QualityRating),
               rmse(pred_reg2, test$QualityRating))

newx <- as.matrix(test[,1:5])
pred_lasso <- predict(lasso, newx)
regresult3 <- c(mae(pred_lasso, test$QualityRating),mse(pred_lasso, test$QualityRating),
               rmse(pred_lasso, test$QualityRating))
rbind(regresult1,regresult2,regresult3)
# mse : 이상치에 패널티가 커짐 -> 기본모형은 이상치에 둔감
# 기본모형보다는 lasso로 활용하면 결과자체에 맞는 경우
#어떻게 평가하는지가 중요함;
```
